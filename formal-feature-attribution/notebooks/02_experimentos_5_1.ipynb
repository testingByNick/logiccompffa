{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1a4a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Experimentos - Se√ß√£o 5.1: Datasets Sint√©ticos\\n\",\n",
    "    \"\\n\",\n",
    "    \"Reprodu√ß√£o dos experimentos com datasets sint√©ticos lineares e n√£o-lineares.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Adiciona src ao path\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from experiments.section_5_1 import run_section_5_1\\n\",\n",
    "    \"from formal_ffa import FormalFFA, HeuristicFFA\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configura√ß√µes de visualiza√ß√£o\\n\",\n",
    "    \"plt.style.use('default')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"%matplotlib inline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Execu√ß√£o dos Experimentos da Se√ß√£o 5.1\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"üöÄ EXECUTANDO EXPERIMENTOS DA SE√á√ÉO 5.1\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"results_5_1 = run_section_5_1()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. An√°lise Detalhada dos Resultados\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"üìä AN√ÅLISE DETALHADA DOS RESULTADOS\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for dataset_name, data in results_5_1.items():\\n\",\n",
    "    \"    print(f\\\"\\\\nüéØ DATASET: {dataset_name.upper()}\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 40)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Performance do modelo\\n\",\n",
    "    \"    perf = data['performance']\\n\",\n",
    "    \"    print(f\\\"üìà Performance do Modelo:\\\")\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Acur√°cia Treino: {perf['train_accuracy']:.3f}\\\")\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Acur√°cia Teste:  {perf['test_accuracy']:.3f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # An√°lise das atribui√ß√µes\\n\",\n",
    "    \"    heuristic_attrs = data['heuristic_attributions']\\n\",\n",
    "    \"    formal_attrs = data['formal_attributions']\\n\",\n",
    "    \"    sample_indices = data['sample_indices']\\n\",\n",
    "    \"    feature_names = data['feature_names']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nüîç An√°lise das Atribui√ß√µes:\\\")\\n\",\n",
    "    \"    for i, idx in enumerate(sample_indices):\\n\",\n",
    "    \"        heuristic_attr = heuristic_attrs[i]\\n\",\n",
    "    \"        formal_attr = formal_attrs[i]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Top features\\n\",\n",
    "    \"        top_heuristic = feature_names[np.argmax(heuristic_attr)]\\n\",\n",
    "    \"        top_formal = feature_names[np.argmax(formal_attr)]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Correla√ß√£o entre m√©todos\\n\",\n",
    "    \"        from scipy.stats import kendalltau\\n\",\n",
    "    \"        corr, _ = kendalltau(heuristic_attr, formal_attr)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"   üìç Inst√¢ncia {idx}:\\\")\\n\",\n",
    "    \"        print(f\\\"      ‚Ä¢ FFA Heur√≠stico: {top_heuristic} ({heuristic_attr.max():.3f})\\\")\\n\",\n",
    "    \"        print(f\\\"      ‚Ä¢ FFA Formal:     {top_formal} ({formal_attr.max():.3f})\\\")\\n\",\n",
    "    \"        print(f\\\"      ‚Ä¢ Correla√ß√£o:     {corr:.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Visualiza√ß√£o Comparativa FFA Heur√≠stico vs Formal\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"üìà VISUALIZA√á√ÉO COMPARATIVA\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for dataset_name, data in results_5_1.items():\\n\",\n",
    "    \"    heuristic_attrs = data['heuristic_attributions']\\n\",\n",
    "    \"    formal_attrs = data['formal_attributions']\\n\",\n",
    "    \"    sample_indices = data['sample_indices']\\n\",\n",
    "    \"    feature_names = data['feature_names']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, idx in enumerate(sample_indices):\\n\",\n",
    "    \"        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # FFA Heur√≠stico\\n\",\n",
    "    \"        ax1.barh(feature_names, heuristic_attrs[i], color='skyblue', alpha=0.7)\\n\",\n",
    "    \"        ax1.set_title(f'FFA Heur√≠stico - {dataset_name} (Inst√¢ncia {idx})', fontweight='bold')\\n\",\n",
    "    \"        ax1.set_xlim(0, 1)\\n\",\n",
    "    \"        ax1.grid(axis='x', alpha=0.3)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # FFA Formal\\n\",\n",
    "    \"        ax2.barh(feature_names, formal_attrs[i], color='lightcoral', alpha=0.7)\\n\",\n",
    "    \"        ax2.set_title(f'FFA Formal - {dataset_name} (Inst√¢ncia {idx})', fontweight='bold')\\n\",\n",
    "    \"        ax2.set_xlim(0, 1)\\n\",\n",
    "    \"        ax2.grid(axis='x', alpha=0.3)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Estat√≠sticas da inst√¢ncia\\n\",\n",
    "    \"        heuristic_attr = heuristic_attrs[i]\\n\",\n",
    "    \"        formal_attr = formal_attrs[i]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        from scipy.stats import kendalltau\\n\",\n",
    "    \"        corr, _ = kendalltau(heuristic_attr, formal_attr)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"üìä Dataset {dataset_name} - Inst√¢ncia {idx}:\\\")\\n\",\n",
    "    \"        print(f\\\"   ‚Ä¢ Correla√ß√£o FFA Heur√≠stico vs Formal: {corr:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"   ‚Ä¢ Features mais importantes:\\\")\\n\",\n",
    "    \"        print(f\\\"     - Heur√≠stico: {feature_names[np.argmax(heuristic_attr)]} ({heuristic_attr.max():.3f})\\\")\\n\",\n",
    "    \"        print(f\\\"     - Formal:     {feature_names[np.argmax(formal_attr)]} ({formal_attr.max():.3f})\\\")\\n\",\n",
    "    \"        print()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. An√°lise de Consist√™ncia entre M√©todos FFA\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"üîç AN√ÅLISE DE CONSIST√äNCIA ENTRE M√âTODOS FFA\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"consistency_analysis = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for dataset_name, data in results_5_1.items():\\n\",\n",
    "    \"    heuristic_attrs = data['heuristic_attributions']\\n\",\n",
    "    \"    formal_attrs = data['formal_attributions']\\n\",\n",
    "    \"    sample_indices = data['sample_indices']\\n\",\n",
    "    \"    feature_names = data['feature_names']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    correlations = []\\n\",\n",
    "    \"    top_feature_agreements = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in range(len(sample_indices)):\\n\",\n",
    "    \"        heuristic_attr = heuristic_attrs[i]\\n\",\n",
    "    \"        formal_attr = formal_attrs[i]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Correla√ß√£o\\n\",\n",
    "    \"        from scipy.stats import kendalltau\\n\",\n",
    "    \"        corr, _ = kendalltau(heuristic_attr, formal_attr)\\n\",\n",
    "    \"        correlations.append(corr)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Concord√¢ncia no top feature\\n\",\n",
    "    \"        top_heuristic = np.argmax(heuristic_attr)\\n\",\n",
    "    \"        top_formal = np.argmax(formal_attr)\\n\",\n",
    "    \"        agreement = top_heuristic == top_formal\\n\",\n",
    "    \"        top_feature_agreements.append(agreement)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    consistency_analysis[dataset_name] = {\\n\",\n",
    "    \"        'avg_correlation': np.mean(correlations),\\n\",\n",
    "    \"        'std_correlation': np.std(correlations),\\n\",\n",
    "    \"        'agreement_rate': np.mean(top_feature_agreements),\\n\",\n",
    "    \"        'n_instances': len(sample_indices)\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nüìà {dataset_name.upper()}:\\\")\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Correla√ß√£o m√©dia: {np.mean(correlations):.3f} (¬±{np.std(correlations):.3f})\\\")\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Taxa de concord√¢ncia no top feature: {np.mean(top_feature_agreements):.1%}\\\")\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ Inst√¢ncias analisadas: {len(sample_indices)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Salvando Resultados para a Se√ß√£o 5.2\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"üíæ SALVANDO RESULTADOS\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pickle\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Cria diret√≥rio se n√£o existir\\n\",\n",
    "    \"os.makedirs('../data/results', exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Salva resultados\\n\",\n",
    "    \"with open('../data/results/section_5_1_results.pkl', 'wb') as f:\\n\",\n",
    "    \"    pickle.dump(results_5_1, f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ Resultados da Se√ß√£o 5.1 salvos em:'../data/results/section_5_1_results.pkl'\\\")\\n\",\n",
    "    \"print(\\\"\\\\nüéØ PR√ìXIMO PASSO: Executar notebook 03_experimentos_5_2.ipynb\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Resumo Executivo\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"üìã RESUMO EXECUTIVO - SE√á√ÉO 5.1\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüéØ OBJETIVOS ATINGIDOS:\\\")\\n\",\n",
    "    \"print(\\\"‚úÖ Gera√ß√£o de datasets sint√©ticos lineares e n√£o-lineares\\\")\\n\",\n",
    "    \"print(\\\"‚úÖ Treinamento de modelos XGBoost conforme especifica√ß√£o do artigo\\\") \\n\",\n",
    "    \"print(\\\"‚úÖ Implementa√ß√£o e compara√ß√£o de FFA Heur√≠stico vs Formal\\\")\\n\",\n",
    "    \"print(\\\"‚úÖ An√°lise de consist√™ncia entre m√©todos de atribui√ß√£o\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìä RESULTADOS OBTIDOS:\\\")\\n\",\n",
    "    \"for dataset_name, consistency in consistency_analysis.items():\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ {dataset_name}:\\\")\\n\",\n",
    "    \"    print(f\\\"     - Correla√ß√£o FFA Heur√≠stico vs Formal: {consistency['avg_correlation']:.3f}\\\")\\n\",\n",
    "    \"    print(f\\\"     - Concord√¢ncia no top feature: {consistency['agreement_rate']:.1%}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüîÆ PR√ìXIMOS PASSOS:\\\")\\n\",\n",
    "    \"print(\\\"   ‚Ä¢ Compara√ß√£o com m√©todos de aproxima√ß√£o (LIME, SHAP) na Se√ß√£o 5.2\\\")\\n\",\n",
    "    \"print(\\\"   ‚Ä¢ An√°lise estat√≠stica das diferen√ßas entre m√©todos\\\")\\n\",\n",
    "    \"print(\\\"   ‚Ä¢ Valida√ß√£o contra resultados reportados no artigo\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"formal-feature-attribution\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
